{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2866869",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Week9 - object detection/data/train/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m test_labels_dir = \u001b[33m\"\u001b[39m\u001b[33mWeek9 - object detection/data/test/labels\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m train_data = \u001b[43mCustomImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m test_data = CustomImageDataset(test_images_dir, test_labels_dir, transform=test_transform)\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Create dataloaders\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mCustomImageDataset.__init__\u001b[39m\u001b[34m(self, images_dir, labels_dir, transform)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.transform = transform\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Get all image files\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mself\u001b[39m.image_files = \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     19\u001b[39m                            \u001b[38;5;28;01mif\u001b[39;00m f.endswith((\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpeg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.JPG\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.PNG\u001b[39m\u001b[33m'\u001b[39m))])\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Read all labels and create class mapping\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.labels = []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Week9 - object detection/data/train/images'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted([f for f in os.listdir(images_dir) \n",
    "                                   if f.endswith(('.png', '.jpg', '.jpeg', '.JPG', '.PNG'))])\n",
    "        \n",
    "        # Read all labels and create class mapping\n",
    "        self.labels = []\n",
    "        all_classes = set()\n",
    "        \n",
    "        for img_file in self.image_files:\n",
    "            # Assume label file has same name but .txt extension\n",
    "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    # Read first line and extract class (assumes YOLO format: class x y w h)\n",
    "                    line = f.readline().strip()\n",
    "                    if line:\n",
    "                        class_id = int(line.split()[0])\n",
    "                        self.labels.append(class_id)\n",
    "                        all_classes.add(class_id)\n",
    "                    else:\n",
    "                        self.labels.append(0)  # Default class if empty\n",
    "            else:\n",
    "                self.labels.append(0)  # Default class if no label file\n",
    "        \n",
    "        # Create sorted list of classes\n",
    "        self.classes = sorted(list(all_classes))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Remap labels to consecutive indices\n",
    "        self.labels = [self.class_to_idx[label] for label in self.labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_images_dir = \"Week9 - object detection/data/train/images\"\n",
    "train_labels_dir = \"Week9 - object detection/data/train/labels\"\n",
    "test_images_dir = \"Week9 - object detection/data/test/images\"\n",
    "test_labels_dir = \"Week9 - object detection/data/test/labels\"\n",
    "\n",
    "# Create datasets\n",
    "train_data = CustomImageDataset(train_images_dir, train_labels_dir, transform=train_transform)\n",
    "test_data = CustomImageDataset(test_images_dir, test_labels_dir, transform=test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of classes: {len(train_data.classes)}\")\n",
    "print(f\"Classes: {train_data.classes}\")\n",
    "\n",
    "# Model setup\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(train_data.classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "Learning_Rate = 0.001  # Define if not already defined\n",
    "optimizer = optim.Adam(model.parameters(), lr=Learning_Rate)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_data)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"resnet18_finetuned.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
